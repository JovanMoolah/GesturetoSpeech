
import ultralytics

import supervision as sv

import cv2

import random

from ultralytics import YOLO

from roboflow import Roboflow

from matplotlib import pyplot as plt

import albumentations as A

import numpy as np

import torch

import os

from sklearn.model_selection import train_test_split

from tqdm import tqdm

import pyttsx3

from itertools import groupby

import argostranslate.package

import argostranslate.translate















'''


#image = cv2.imread('test.jpg')
#cv2.imshow("NAME", image)
#cv2.waitKey(0)


KEYPOINT_COLOR = (0, 255, 0) # Green

def vis_keypoints(image, keypoints, color=KEYPOINT_COLOR, diameter=5):
    image = image.copy()

    for (x, y) in keypoints:
        cv2.circle(image, (int(x), int(y)), diameter, (0, 255, 0), -1)

    plt.figure(figsize=(8, 8))
    plt.axis('off')
    plt.imshow(image)
    plt.show()
   

image = cv2.imread('test.jpg')
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
h, w, _ = image.shape




bboxes = []
classlabels = []
keypoints = []

with open('test.txt', 'r') as f:
    for line in f:
            data = list(map(float, line.strip().split()))
            if len(data) == 68: 
                class_id = int (data[0])
                classlabels.append(class_id)
                bbox = data[1:5]
                bboxes.append(bbox)
                keypoint_data = data[5:]
                for i in range(0, len(keypoint_data), 3):
                    kdata = [keypoint_data[i], keypoint_data[i+1],keypoint_data[i+2]] 
                    #kdatan = kdata(range(0, 62, 3)) 
                    keypoints.append (kdata) 



keypoints = [(h*a, h*b) for a, b, c in keypoints]   


with open('List.txt', 'w') as f:
                for line in keypoints:
                    f.write(f"{line}\n")
     


vis_keypoints(image, keypoints)

transform = A.Compose(
    [A.VerticalFlip(p=1)],
    keypoint_params=A.KeypointParams(format='xy')
)
transformed = transform(image=image, keypoints=keypoints)
vis_keypoints(transformed['image'], transformed['keypoints'])



#random.seed()
#transform = A.Compose(
 #   [A.Rotate(p=1)],
  #  keypoint_params=A.KeypointParams(format='xy')
#)
#transformed = transform(image=image, keypoints=keypoints)
#vis_keypoints(transformed['image'], transformed['keypoints'])




def load_images_from_folder(folder):
    images = []
    for filename in os.listdir(folder):
        img = cv2.imread(os.path.join(folder,filename))
        if img is not None:
            images.append(img)
    return images



reference_image = cv2.imread(r'L:\Python Data\PoseTesting\PoseTesting\reference\pexels-photo-164595.jpeg')

transform = A.Compose([
     A.HistogramMatching (reference_images=[load_images_from_folder(r'L:\Python Data\PoseTesting\PoseTesting\reference')],blend_ratio=(0.5, 1.0),read_fn=lambda x: x,p=1)],
     keypoint_params=A.KeypointParams(format='xy')
)
transformed = transform(image=image, keypoints=keypoints)
vis_keypoints(transformed['image'], transformed['keypoints'])



'''
